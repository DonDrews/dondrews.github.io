<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Don's Projects</title><link>https://dondrews.github.io/</link><description>Recent content on Don's Projects</description><generator>Hugo -- gohugo.io</generator><language>en</language><lastBuildDate>Sun, 07 Sep 2025 00:00:00 +0000</lastBuildDate><atom:link href="https://dondrews.github.io/index.xml" rel="self" type="application/rss+xml"/><item><title>Eggplant Casserole</title><link>https://dondrews.github.io/recipes/eggplant-casserole/</link><pubDate>Sun, 07 Sep 2025 00:00:00 +0000</pubDate><guid>https://dondrews.github.io/recipes/eggplant-casserole/</guid><description>&lt;p&gt;This recipe is inspired by eggplant parmesan, but with a Southwestern twist. Serves 2.&lt;/p&gt;
&lt;h3 id="ingredients"&gt;Ingredients&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;3 Japanese eggplant, cut into rounds (If using American eggplant, salt and drain them first to remove bitterness)&lt;/li&gt;
&lt;li&gt;3 small slicing tomatoes&lt;/li&gt;
&lt;li&gt;1 small red onion, finely chopped&lt;/li&gt;
&lt;li&gt;3/4 cup chopped cooked chicken (I used 2 thighs)&lt;/li&gt;
&lt;li&gt;1 jalape単o, minced&lt;/li&gt;
&lt;li&gt;2 garlic cloves, minced&lt;/li&gt;
&lt;li&gt;1 cup grated colby jack cheese, or to taste&lt;/li&gt;
&lt;li&gt;2 tsps extra virgin olive oil&lt;/li&gt;
&lt;li&gt;1/2 tsp salt&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="procedure"&gt;Procedure&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;Blanch the tomatoes in a small saucepan for a couple minutes to loosen the skins, then drain and let cool.&lt;/li&gt;
&lt;li&gt;In the emptied saucepan, heat the olive oil and then add the garlic, jalape単o, onions. Saute on medium heat.&lt;/li&gt;
&lt;li&gt;While the other ingredients are cooking, peel and dice the tomatoes.&lt;/li&gt;
&lt;li&gt;Once the onions are translucent, add the tomatoes and salt. Simmer this on low for about 30-45 minutes or until the tomatoes are mostly disintegrated and the sauce has thickened up. During this period preheat the oven to 400 degrees Fahrenheit.&lt;/li&gt;
&lt;li&gt;After the sauce is ready, the casserole can be assembled. In a 8&amp;quot;x8&amp;quot; baking dish, add a layer of half the eggplant, then half the chicken, and likewise half the sauce. Repeat this for 3 more layers. Top the dish with the grated cheese, for me this ended up being about 1&amp;quot; thick.&lt;/li&gt;
&lt;li&gt;Bake the casserole for 25 minutes or until the cheese starts to brown. Cool for 5 minutes then serve.&lt;/li&gt;
&lt;/ol&gt;</description><content>&lt;p&gt;This recipe is inspired by eggplant parmesan, but with a Southwestern twist. Serves 2.&lt;/p&gt;
&lt;h3 id="ingredients"&gt;Ingredients&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;3 Japanese eggplant, cut into rounds (If using American eggplant, salt and drain them first to remove bitterness)&lt;/li&gt;
&lt;li&gt;3 small slicing tomatoes&lt;/li&gt;
&lt;li&gt;1 small red onion, finely chopped&lt;/li&gt;
&lt;li&gt;3/4 cup chopped cooked chicken (I used 2 thighs)&lt;/li&gt;
&lt;li&gt;1 jalape単o, minced&lt;/li&gt;
&lt;li&gt;2 garlic cloves, minced&lt;/li&gt;
&lt;li&gt;1 cup grated colby jack cheese, or to taste&lt;/li&gt;
&lt;li&gt;2 tsps extra virgin olive oil&lt;/li&gt;
&lt;li&gt;1/2 tsp salt&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="procedure"&gt;Procedure&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;Blanch the tomatoes in a small saucepan for a couple minutes to loosen the skins, then drain and let cool.&lt;/li&gt;
&lt;li&gt;In the emptied saucepan, heat the olive oil and then add the garlic, jalape単o, onions. Saute on medium heat.&lt;/li&gt;
&lt;li&gt;While the other ingredients are cooking, peel and dice the tomatoes.&lt;/li&gt;
&lt;li&gt;Once the onions are translucent, add the tomatoes and salt. Simmer this on low for about 30-45 minutes or until the tomatoes are mostly disintegrated and the sauce has thickened up. During this period preheat the oven to 400 degrees Fahrenheit.&lt;/li&gt;
&lt;li&gt;After the sauce is ready, the casserole can be assembled. In a 8&amp;quot;x8&amp;quot; baking dish, add a layer of half the eggplant, then half the chicken, and likewise half the sauce. Repeat this for 3 more layers. Top the dish with the grated cheese, for me this ended up being about 1&amp;quot; thick.&lt;/li&gt;
&lt;li&gt;Bake the casserole for 25 minutes or until the cheese starts to brown. Cool for 5 minutes then serve.&lt;/li&gt;
&lt;/ol&gt;</content></item><item><title>Summer Veggie Pasta</title><link>https://dondrews.github.io/recipes/summer-veggie-pasta/</link><pubDate>Wed, 02 Jul 2025 00:00:00 +0000</pubDate><guid>https://dondrews.github.io/recipes/summer-veggie-pasta/</guid><description>&lt;p&gt;I made this dish while at SouthWinds Farm due to an excess of carrots and summer squash. It is a simple, not exactly healthy, but certainly hearty dish. Serves 2.&lt;/p&gt;
&lt;h3 id="ingredients"&gt;Ingredients&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;8oz dried pasta&lt;/li&gt;
&lt;li&gt;1 medium summer squash, chopped into rounds&lt;/li&gt;
&lt;li&gt;2 medium carrots, chopped into rounds&lt;/li&gt;
&lt;li&gt;1 Italian sausage&lt;/li&gt;
&lt;li&gt;4 tbsp salted butter&lt;/li&gt;
&lt;li&gt;2 garlic cloves, minced&lt;/li&gt;
&lt;li&gt;1/2 cup crumbled feta cheese&lt;/li&gt;
&lt;li&gt;black pepper&lt;/li&gt;
&lt;li&gt;Italian seasoning&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="procedure"&gt;Procedure&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;Cook the pasta according to package directions while performing the rest of the steps.&lt;/li&gt;
&lt;li&gt;Brown the extruded sausage over medium heat in a non-stick pan, while crumbling into bite-sized pieces.&lt;/li&gt;
&lt;li&gt;Set aside the sausage, leaving the grease in the pan. Add the butter to this grease.&lt;/li&gt;
&lt;li&gt;Add the carrots to the greasy pan, and saute for ~5 minutes.&lt;/li&gt;
&lt;li&gt;Add the summer squash and garlic to the pan, continue sauteing for ~8 minutes, or until the squash is softened. Stir in a generous pinch of black pepper and Italian seasoning.&lt;/li&gt;
&lt;li&gt;Combine with the pasta, then add back the sausage along with the feta cheese.&lt;/li&gt;
&lt;li&gt;Serve hot.&lt;/li&gt;
&lt;/ol&gt;</description><content>&lt;p&gt;I made this dish while at SouthWinds Farm due to an excess of carrots and summer squash. It is a simple, not exactly healthy, but certainly hearty dish. Serves 2.&lt;/p&gt;
&lt;h3 id="ingredients"&gt;Ingredients&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;8oz dried pasta&lt;/li&gt;
&lt;li&gt;1 medium summer squash, chopped into rounds&lt;/li&gt;
&lt;li&gt;2 medium carrots, chopped into rounds&lt;/li&gt;
&lt;li&gt;1 Italian sausage&lt;/li&gt;
&lt;li&gt;4 tbsp salted butter&lt;/li&gt;
&lt;li&gt;2 garlic cloves, minced&lt;/li&gt;
&lt;li&gt;1/2 cup crumbled feta cheese&lt;/li&gt;
&lt;li&gt;black pepper&lt;/li&gt;
&lt;li&gt;Italian seasoning&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="procedure"&gt;Procedure&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;Cook the pasta according to package directions while performing the rest of the steps.&lt;/li&gt;
&lt;li&gt;Brown the extruded sausage over medium heat in a non-stick pan, while crumbling into bite-sized pieces.&lt;/li&gt;
&lt;li&gt;Set aside the sausage, leaving the grease in the pan. Add the butter to this grease.&lt;/li&gt;
&lt;li&gt;Add the carrots to the greasy pan, and saute for ~5 minutes.&lt;/li&gt;
&lt;li&gt;Add the summer squash and garlic to the pan, continue sauteing for ~8 minutes, or until the squash is softened. Stir in a generous pinch of black pepper and Italian seasoning.&lt;/li&gt;
&lt;li&gt;Combine with the pasta, then add back the sausage along with the feta cheese.&lt;/li&gt;
&lt;li&gt;Serve hot.&lt;/li&gt;
&lt;/ol&gt;</content></item><item><title>USB Audio Interface</title><link>https://dondrews.github.io/posts/audio-interface/</link><pubDate>Sun, 08 Oct 2023 00:00:00 +0000</pubDate><guid>https://dondrews.github.io/posts/audio-interface/</guid><description>&lt;p&gt;For a long time I&amp;rsquo;d wanted to make an audio interface for recording music and voice calls on my computer. It seemed like the ideal next step from making analog guitar effects pedals and some small microcontroller projects. I finally had the perfect opportunity in my last semester during the course &lt;em&gt;CSE 145: Embedded Systems Design Project&lt;/em&gt;. The course is long over by the time I&amp;rsquo;ve gotten around to writing this post, but I&amp;rsquo;m happy to report that I still use this interface daily.&lt;/p&gt;</description><content>&lt;p&gt;For a long time I&amp;rsquo;d wanted to make an audio interface for recording music and voice calls on my computer. It seemed like the ideal next step from making analog guitar effects pedals and some small microcontroller projects. I finally had the perfect opportunity in my last semester during the course &lt;em&gt;CSE 145: Embedded Systems Design Project&lt;/em&gt;. The course is long over by the time I&amp;rsquo;ve gotten around to writing this post, but I&amp;rsquo;m happy to report that I still use this interface daily.&lt;/p&gt;
&lt;h2 id="background"&gt;Background&lt;/h2&gt;
&lt;p&gt;The below sections detail some general information I gathered for this design. Hopefully it can be useful to others starting on audio electronics.&lt;/p&gt;
&lt;h3 id="difference-between-audio-sources"&gt;Difference between audio sources&lt;/h3&gt;
&lt;p&gt;All analog audio sources function by oscillating a voltage or a current to represent sound. However, the specific differences between different types of sources requires consideration and in some cases special handling from the perspective of amplifier design. For the purposes of an audio interface, there are several categories which we are concerned with:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Dynamic microphones&lt;/li&gt;
&lt;li&gt;Condenser microphones&lt;/li&gt;
&lt;li&gt;Pickup instruments&lt;/li&gt;
&lt;li&gt;Line-level audio&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;These can be grouped into the coarser categories of balanced and unbalanced audio, with the microphones generally being balanced, and the other two unbalanced. &amp;ldquo;Balanced&amp;rdquo; audio refers to the fact that these sources use cables in which both the negative and positive signal wires are near-identical in construction, with shielding connected to ground. This topology ensures that any interference along the cable length - either from capacitive coupling or EM sources - applies equally to both polarities. This &amp;ldquo;common-mode&amp;rdquo; interference can then be eliminated by a differential amplifier on the receiving end of the cable. The concept is well illustrated by the diagram from &lt;a href="https://hackaday.com/2016/03/29/when-difference-matters/"&gt;Hackaday&lt;/a&gt; below. On the other hand, unbalanced audio references the positive signal to ground, by connecting the shielding to the negative terminal on the source side, and to ground on the receiving side. The shielding still provides some resistance to interference, and these sources can be used with standard amplifiers. Microphones generally use balanced cables due to the low signal levels present on their output, though this is not as much of a concern for pickup instruments or line-level audio. The prototypical balanced cable for audio purposes is the XLR cable, which has three terminals for positive, negative, and ground.&lt;/p&gt;
&lt;p&gt;&lt;img src="https://dondrews.github.io/img/audio_interface/diff4.webp" alt="Differential signaling"&gt;&lt;/p&gt;
&lt;p&gt;Dynamic microphones are a class of microphone that approximately functions as a speaker cone in reverse. There is a sealed diaphragm which is mechanically attached to an electromagnet. Changing pressure in the air causes the diaphragm to move, which then generates electric current by moving the electromagnet relative to a permanent magnet installed in the microphone. These sources have low sensitivity but also low impedance, on the order of 100 ohms. However, due to the inductive nature of the source, the preamplifier needs a comparatively large input impedance to avoid affecting the frequency response. These microphones have low sensitivity but are also inexpensive, making them very popular for recording instrument amplifiers and drums.&lt;/p&gt;
&lt;p&gt;Condenser microphones function by a different mechanism. They form a capacitor from a thin metallic membrane and a stationary plate. Changing sound pressure causes this membrane to move, which alters the capacitance, generating a current. This topology is very high impedance, and also requires an external bias voltage to function, where 48 volts is the industry standard level. In order to lessen the difficulties with interfacing with high impedance sources, many condenser microphones contain an integrated FET for impedance matching, which is powered off the bias voltage. Condenser microphones are far more sensitive than dynamic microphones, and are common for recording voices. These are an extremely common type of microphone, but were not supported for this project due to the additional technical challenges associated with generating and exposing 48 volts.&lt;/p&gt;
&lt;p&gt;Pickup instruments generate voltages based on the movements of metallic strings or tines next to an electromagnet, or from the compression of a piezoelectric material attached to a vibrating surface. Usually these transducers are referenced to ground, leading to an unbalanced audio source as discussed above. These sources are also low impedance, but must be matched with a high-impedance amplifier to preserve the frequency response. The standard connector for these types of sources is a 1/4&amp;quot; TS cable, and they are found in most electronic string instruments, and some drum microphones.&lt;/p&gt;
&lt;p&gt;Lastly, line-level audio is an term which represents audio sources that are already amplified up to working voltages and currents. The range varies, but generally line-level sources have a maximum amplitude of approximately one volt. This is the easiest type of source to interface with, as no amplification or impedance matching is necessary before digitizing.&lt;/p&gt;
&lt;h3 id="usb-audio"&gt;USB Audio&lt;/h3&gt;
&lt;p&gt;One of the major advantages of USB is the device class system. This part of the specification defines a standard set of types of devices and their associated sub-protocols. For example, there are device classes for mass storage, human interface devices (such as mice and keyboards), printers, cameras, and hundreds of others. These classes cover the majority of use cases for USB. If a device is compliant with the device class specification, then it will generally work with any host operating system, making significantly less work for host driver implementers and device creators. This &amp;ldquo;plug-and-play&amp;rdquo; nature of USB devices is one of the major selling points of the standard, and has led to its wide adoption.&lt;/p&gt;
&lt;p&gt;One of the device classes called USB Audio Device Class 2.0 (UAC) supports a wide variety of audio peripherals. By designing an audio interface to comply with this standard, no host drivers need to be written, and the device should seamlessly function with any host configuration.&lt;/p&gt;
&lt;p&gt;There are several different transaction types defined in the USB standard: control, interrupt, isochronous, and bulk. Each transaction type is suited for a different use case, and isochronous transfers are specifically tailored for streaming applications. For the purposes of creating an audio interface, these and control transfers are the only necessary types. Isochronous endpoints are special in that they do not have any error checking or re-transmission in the protocol. This ensures the minimum latency possible, which is critically important for audio applications.&lt;/p&gt;
&lt;h3 id="analog-digital-conversion"&gt;Analog-Digital Conversion&lt;/h3&gt;
&lt;p&gt;The most important aspect of an audio interface is the conversion from analog to digital with the smallest amount of distortion or noise. Generally this is done using a discrete integrated circuit (IC) that continuously samples the analog lines and outputs digital representations. There are several architectures for ADCs, with the most common being successive approximation register (SAR) and delta-sigma. These two architectures have vastly different internal structures and methods of operation, the specifics of which are out of scope, but this &lt;a href="https://www.analog.com/en/analog-dialogue/articles/the-right-adc-architecture.html"&gt;article&lt;/a&gt; by Analog has some good info. It suffices to say that delta-sigma ADCs are more common for audio applications, because of higher bit resolutions and less stringent anti-aliasing requirements.&lt;/p&gt;
&lt;p&gt;Irrespective of architecture, there are two primary design considerations for using ADCs. One is that ADCs generally have a low input impedance, and require a substantial amount of current from the previous analog stage. Even if the signal is already at the correct line level, a buffer is still required to drive the ADC inputs. The second is that high-frequency content will be aliased back into the frequency range of interest after digitization, usually appearing as noise. Therefore, it is important to have a low-pass anti-aliasing filter before signals enter the ADC. For audio purposes the range of interest is 20Hz to 20kHz, with a sampling frequency of 44.1 or 48kHz, so the -3dB point of the filter is usually placed between 20-40kHz.&lt;/p&gt;
&lt;h2 id="design"&gt;Design&lt;/h2&gt;
&lt;p&gt;The systems diagram below describes the amplifier stages and power tree based upon the above considerations. The external voltage rail is assumed to be noisy, and the negative rail will contain switching noise. Therefore both are isolated from the analog supply by an LDO (low-dropout linear regulator). The balanced XLR input has an additional difference amplifier to provide additional gain as well as eliminating the common-mode interference. Both channels pass through single-ended adjustable amplifiers, where external potentiometers adjust the gain. The summing amplifier adjusts the DC bias level to bring the full wavelength above zero volts, in order to bring the input to a safe level for the ADC. This ADC is attached to a USB-supporting microcontroller which passes the data to the host. The specific details of electrical, firmware, and mechanical design which enable this system are described in the following sections.&lt;/p&gt;
&lt;p&gt;&lt;img src="https://dondrews.github.io/img/audio_interface/sys_diagram.png" alt="System architecture of the audio interface"&gt;&lt;/p&gt;
&lt;h3 id="electrical"&gt;Electrical&lt;/h3&gt;
&lt;p&gt;The electrical design of this audio interface can be broken into three separate categories: analog, digital, and power. For analog, the primary considerations are providing enough gain, and reducing the amount of noise. The microphone used for testing this project was the &lt;em&gt;Shure SM57&lt;/em&gt;, an extremely common and prototypical dynamic microphone. According to the specifications, this microphone has a sensitivity of 56mV/Pa. A more familiar metric would be that a standard speaking volume of 55dB SPL produces an output of 0.6mV. Therefore approximately 80dB of gain would be sufficient for the XLR signal path. This was split evenly across the differential and adjustable stages. For the instrument input, a unity gain is necessary to support line-level audio, and an electric guitar pickup produces approximately 100mVpp output. For consistency, both adjustable stages were designed for 40dB maximum gain and 0dB minimum gain.&lt;/p&gt;
&lt;p&gt;In amplifier design, the intrinsic thermal noise generated by resistors can be a significant contributor to the overall noise profile. This thermal noise has a voltage that is linearly proportional to heat as well as resistance. Therefore, it is best practice to reduce the resistances used in the amplifier feedback loop and filters to the minimum level without loading the op-amps. This is especially important for the resistors in the difference amplifier, since the signal amplitudes are very low at this stage. The higher currents resulting from this choice have an additional noise benefit, as it reduces the effect of shot noise as well as capacitively or inductively coupled noise from the environment. The amplifiers were constructed with 4 &lt;em&gt;TI OPA2134&lt;/em&gt; op-amps, which were chosen for low noise and high power supply rejection ratio (PSRR).&lt;/p&gt;
&lt;p&gt;The digital design of the interface hinged on the choice of microcontroller and ADC. For the microcontroller, the &lt;em&gt;STM32F042&lt;/em&gt; was chosen due to the hand-solderable package, USB support, and price. In addition this microcontroller had an I2S peripheral for interfacing with the ADC. The ADC chosen was the &lt;em&gt;TI PCM4202&lt;/em&gt;, which provided two channels at 24 bits each, and a total harmonic distortion + noise (THD+N) of -105dB. This ADC is designed specifically for audio purposes, which brings several important features such as DC bias removal through an internal digital high-pass filter.&lt;/p&gt;
&lt;p&gt;Delivering power to all these components required multiple different voltage rails. All op-amps were powered off the linearly regulated +7v and -7v rails, generated from low-noise LDOs. The negative voltage were generated by a switching regulator in Cuk configuration, again to reduce noise. The analog and digital 5v and 3.3v rails were both generated with higher-power LDOs. Usually a digital rail would be generated with another switching regulator, but a linear regulator was chosen to reduce to total amount of switching noise on the board, as well as reduce design complexity. In a future redesign I&amp;rsquo;d like to power everything through USB, and in that case the higher efficiency of the swtiching regulator would trade more favorably.&lt;/p&gt;
&lt;p&gt;The high-level layout of the printed circuit board (PCB) brought all connectors to the front edge to simplify mechanical design. In addition, digital and switching circuitry was spatially isolated from sensitive analog circuitry, as can be seen in the layout below. A significant number of test points and jumpers were added to aid testing and verification of the board after assembly.&lt;/p&gt;
&lt;p&gt;&lt;img src="https://dondrews.github.io/img/audio_interface/layout.png" alt="Layout of the PCB"&gt;&lt;/p&gt;
&lt;h3 id="firmware"&gt;Firmware&lt;/h3&gt;
&lt;p&gt;The &lt;a href="https://github.com/DonDrews/audio_interface_cse145/blob/main/audio_usb_test/Core/Src/main.c"&gt;firmware&lt;/a&gt; running on the microcontroller has 3 main tasks:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Gather samples from the ADC, and move them into USB packets for transmission to the host.&lt;/li&gt;
&lt;li&gt;Handle USB control and enumeration signals.&lt;/li&gt;
&lt;li&gt;Control the clipping LEDs.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The first of these tasks is accomplished through the use of the I2S peripheral and direct memory access module (DMA). The I2S peripheral generates control signals for the ADC and receives the samples in a bit-serial fashion. The DMA is then configured to move these samples into a circular buffer located in main memory upon each reception. This circular buffer is the hand-off point to the USB side of the firmware stack.&lt;/p&gt;
&lt;p&gt;The &lt;a href="https://docs.tinyusb.org/en/latest/"&gt;tinyUSB&lt;/a&gt; library was used to implement most of the USB functionality. This is a middleware library that abstracts hardware-specific USB functionality into a generalized software API. USB device, configuration, and endpoint descriptors were created and made accessible to the host through tinyUSB. These allow the host to determine the name, manufacturer, device class, and specific audio attributes of the interface. Isochronous endpoint support in not included in the driver for stm32 in tinyUSB, so support for this endpoint and transfer type was added to a local fork of the library. I am hoping to upstream this change but have not found the time as of yet.&lt;/p&gt;
&lt;p&gt;After each 1ms USB frame, the last millisecond of audio data is parsed in the circular buffer to determine if the clipping threshold has been exceeded, and to fix endianness issues created by the DMA copying. If the audio is clipping, the LED is turned on for the next 200ms to notify the user. This parsed data is then moved into a tinyUSB FIFO, where it is eventually placed into the stm32&amp;rsquo;s packet buffer memory region. On the stm32 architecture, isochronous endpoints use double buffering to achieve maximum throughput for streaming applications such as audio.&lt;/p&gt;
&lt;h3 id="mechanical"&gt;Mechanical&lt;/h3&gt;
&lt;p&gt;An enclosure for the PCB is essential to prevent both mechanical damage as well as ESD. The primary consideration in the mechanical layout was ease of assembly and disassembly. For this reason, all connectors are attached to only the front plate of the enclosure, so that the PCB can be entirely removed by only removing one face of the enclosure. In this same vein, the front and back plates are connected with M3 hex bolts to allow for many cycles of attachment and detachment without mechanical failure. For durability the sides of the enclosure are constructed with 1/4&amp;quot; oak boards, and the front and back plates with 1/8&amp;quot; brushed aluminum sheet metal. Both front and back plates were modeled in the CAD program &lt;em&gt;Fusion360&lt;/em&gt; before being CNC routed and attached to the wooden side panels, as seen in the cover image.&lt;/p&gt;
&lt;p&gt;&lt;img src="https://dondrews.github.io/img/audio_interface/cad.png" alt="The CAD for the faceplate"&gt;&lt;/p&gt;
&lt;h2 id="results"&gt;Results&lt;/h2&gt;
&lt;p&gt;SNR measures the ratio of the difference in amplitude between the signal when at full scale, and the noise floor. It is a common way of measuring the amount of useful information that can be derived from a signal. Usually, the measurement is specified in dB and has an associated bandwidth over which the noise is collected. For audio, this band is assumed to be 20Hz-20kHz. However, this is a poor proxy for audio quality, as many other effects can lead to audible degradation, such as distortion. Total harmonic distortion (THD) is another measurement that quantifies the amount of distortion in a signal. The measurement is performed by inputting a sinusoid of a known frequency into a system, and then recording the output. Then, Fourier analysis is used to compare the power present in the fundamental frequency as opposed to the sum of all integer harmonics of that frequency. This is a very common measurement in power electronics, RF engineering, and amplifier design.&lt;/p&gt;
&lt;p&gt;One of the most useful measurements of audio quality combines these two metrics into &amp;ldquo;total harmonic distortion and noise&amp;rdquo; or (THD + N). Sometimes it is also referred to in the inverse ratio form as &amp;ldquo;signal to noise and distortion ratio&amp;rdquo; (SINAD). This is performed by inputting a sinusoid into the system, and then applying a notch filter at that frequency to the output. The ratio between the total power in the unfiltered and filtered signals is the SINAD, and is a good proxy for the audible quality of the system. In order to provide a closer representation of perceptible audio quality, sometimes &amp;ldquo;A-weighting&amp;rdquo; is applied to the output, which scales the power at each frequency based on the perceived loudness by the human ear. Generally, this means attenuating the very high and very low frequencies, while amplifying the mid-range. For the purposes of this project, SINAD is used as the primary measurement of quality, but without A-weighting.&lt;/p&gt;
&lt;p&gt;The audio interface was measured to have a SINAD of 45dB on the instrument channel and 27dB on the microphone channel. When viewing the frequency plot for the instrument input below, it can be seen that most of the SINAD reduction is due to the harmonic distortion and not the noise. These measurements fall short of the specification, and there are several theories as to the cause. One of the most likely candidates for the poor performance of the microphone input centers around the crosstalk between channels, which is approximately 30dB. When the instrument input is floating, the high impedance source amplifies EMI to nearly full-scale, and this carries over to the microphone input during testing. A fix was applied to resolve this issue, but additional testing did not take place after this change was made. Another possible cause for both channels is the mismatch between the real and expected ADC sampling frequency, which is 46.7kHz as opposed to 48kHz. This means the OS must pick up the slack of interpolating these samples, which could lead to all sorts of hidden issues.&lt;/p&gt;
&lt;p&gt;&lt;img src="https://dondrews.github.io/img/audio_interface/dist.png" alt="Measured spectrum of the tone"&gt;&lt;/p&gt;
&lt;h2 id="future"&gt;Future&lt;/h2&gt;
&lt;p&gt;This project went more seamlessly than I had expected, but there is still a lot I would like to improve on in a future revision. High on the list is adding support for condenser microphones, as they are the most commonly used for high-precision recordings. In the last year of use I have also noticed an occasional clicking noise, which I think can be attributed to the sampling rate issue above. Powering entirely off of the USB Vbus would also improve the usability significantly.&lt;/p&gt;
&lt;p&gt;Here&amp;rsquo;s a demo created by a good friend of mine who used the interface to record electric bass, drums, and Rhodes piano to demonstrate the audio quality. (We accidentally left the metronome in!)&lt;/p&gt;
&lt;figure &gt;
&lt;audio controls preload="metadata"&gt;
&lt;source src="https://dondrews.github.io/demo.mp3" type="audio/mpeg"&gt;
&lt;/audio&gt;
&lt;figcaption&gt;Demo (Vulfpeck - Beastly cover)&lt;/figcaption&gt;
&lt;/figure&gt;</content></item><item><title>Iterative BVP Solvers on FPGAs</title><link>https://dondrews.github.io/posts/iterative-bvp-solvers-on-fpgas/</link><pubDate>Wed, 01 Dec 2021 00:00:00 +0000</pubDate><guid>https://dondrews.github.io/posts/iterative-bvp-solvers-on-fpgas/</guid><description>&lt;p&gt;For the course MATH179: Projects in Computational and Applied Mathematics at UCSD, I spent some time looking into accelerating ODE boundary value problem solvers on an FPGA. Unfortunately, this took place before I had learned of HLS, so it was &lt;a href="https://github.com/DonDrews/de-on-fpga/tree/main/deon_fpga.srcs/sources_1/new"&gt;written entirely in Verilog.&lt;/a&gt; I have slightly adapted my report for that course below to hopefully show some general practices about how FPGAs can be applied to HPC tasks. It is definitely worth noting that due to time constraints, this problem is very contrived, as linear ODE BVPs can be solved directly. However, the idea of using FPGAs for PDE BVPs with somewhat similar techniques is an active area of research.&lt;/p&gt;</description><content>&lt;p&gt;For the course MATH179: Projects in Computational and Applied Mathematics at UCSD, I spent some time looking into accelerating ODE boundary value problem solvers on an FPGA. Unfortunately, this took place before I had learned of HLS, so it was &lt;a href="https://github.com/DonDrews/de-on-fpga/tree/main/deon_fpga.srcs/sources_1/new"&gt;written entirely in Verilog.&lt;/a&gt; I have slightly adapted my report for that course below to hopefully show some general practices about how FPGAs can be applied to HPC tasks. It is definitely worth noting that due to time constraints, this problem is very contrived, as linear ODE BVPs can be solved directly. However, the idea of using FPGAs for PDE BVPs with somewhat similar techniques is an active area of research.&lt;/p&gt;
&lt;h1 id="introduction"&gt;Introduction&lt;/h1&gt;
&lt;p&gt;The example problem in our implementation is the linear boundary value problem.&lt;/p&gt;
&lt;p&gt;$$\begin{cases} y&amp;rsquo;&amp;rsquo; - y = 0 \\ y(0)=1 \\ y(8)=0.5 \end{cases}$$&lt;/p&gt;
&lt;p&gt;This system can easily be solved analytically, and therefore is a good benchmark to verify the accuracy of our implementation. There are many ways in which to construct an iterative solver for this system. Due to the numerical instability inherent to the system as well as ease of development, we opted for a finite difference method for discretization followed by a basic Jacobi solver.&lt;/p&gt;
&lt;p&gt;The FDM is identical to the method presented in these &lt;a href="https://web.mit.edu/10.001/Web/Course_Notes/Differential_Equations_Notes/node9.html"&gt;course notes&lt;/a&gt; which we will briefly outline. By taking the Taylor expansions of $y(t)$ and rearranging terms to approximate the second derivative we arrive at&lt;/p&gt;
&lt;p&gt;$$\frac{y(t + h) - 2y(t) + y(t - h)}{2h} - y(t) = 0$$&lt;/p&gt;
&lt;p&gt;When using a discretization such that $x_{i+1} - x_i = h$ this can be written&lt;/p&gt;
&lt;p&gt;$$\frac{y_{i+1} - 2y_i + y_{i-1}}{2h} - y_i = 0$$&lt;/p&gt;
&lt;p&gt;By combining these approximations to the system at each point in the domain together, we get a banded square matrix with as many columns and rows as there are points in the domain. This matrix also has only one non-zero entry on the diagonal in the first and last rows, to account for the boundary conditions. Constructing a Jacobi iteration scheme based on this matrix leads to the following equations&lt;/p&gt;
&lt;p&gt;$$\hat{y_{i}} = \begin{cases} 1 &amp;amp; i = 0 \\ (y_{i-1} + y_{i+1}) \times (2 + h^2)^{-1} &amp;amp; 0 &amp;lt; i &amp;lt; n \\ 0.5 &amp;amp; i = n \end{cases}$$&lt;/p&gt;
&lt;p&gt;Where $\hat{y}$ represents the next iteration&amp;rsquo;s approximation in the algorithm. Note that this computation requires only a single multiplication and addition per index per iteration, which lends well to FPGA implementation.&lt;/p&gt;
&lt;h1 id="data-types-and-matlab-simulation"&gt;Data Types and MATLAB Simulation&lt;/h1&gt;
&lt;p&gt;Unlike traditional processors and GPUs where computations are most efficient when using the native bit-width of the system or floating point, FPGAs have much more flexibility to use smaller data types when this level of precision is not necessary. Using smaller data types leads to less area utilization and power usage. The relative lack of dedicated floating point hardware on FPGAs has also led to a wide adoption of fixed-point arithmetic for applications in DSP, control systems, and others. These fixed-point data types use a set amount of bits in the number for the integer portion, and the rest for the fractional part. For example, a common fixed-point data type used in FIR filters is &amp;ldquo;Q15&amp;rdquo;, which uses 16 bits to represent a signed number from -1 to 1 with an epsilon of $2^{-15}$.&lt;/p&gt;
&lt;p&gt;For the purposes of this linear solver, we simulated the algorithm in MATLAB using a variety of data types in order to determine the necessary precision for the algorithm to converge. What we found was that a Q4.12 fixed point representation was sufficiently precise for the algorithm to remain stable. The main bottleneck in this regard is the very small intermediary value in the calculation of the second derivative approximation as the number of points in the discretization increases.&lt;/p&gt;
&lt;p&gt;Additionally, in MATLAB we tested to see if the SOR algorithm could be utilized to improve on the convergence time of the Jacobi iteration. Unfortunately, the system is only slightly diagonally dominant, and SOR does not converge for any relaxation factor $\omega &amp;gt; 1$ in fixed point arithmetic.&lt;/p&gt;
&lt;h1 id="system-architecture"&gt;System Architecture&lt;/h1&gt;
&lt;p&gt;&lt;img src="https://dondrews.github.io/img/fpga_sys_dia.png" alt="System Architecture Diagram"&gt;&lt;/p&gt;
&lt;p&gt;The general architecture for our implementation involves using the existing DSP resources on the FPGA and controlling them using logic in the fabric described with Verilog HDL. The data is sent and received from the interface computer using serial over USB. The current approximation is stored in a series of dual port block RAM resources. The current implementation for the example ODE involves a 128 point uniform discretization, with 16 points stored in each BRAM, and one DSP slice per BRAM. As shown in the above figure, each DSP slice is connected to the BRAM before and after it. This allows for sampling the indices just before and after the first and last index stored in the BRAM, which is necessary for the algorithm. It would be easy to scale this approach to much larger domains, the only limitation being the number of DSP slices, BRAMs, and the capacity of each BRAM.&lt;/p&gt;
&lt;p&gt;The goal of using multiple BRAMs is to overcome the main bottleneck on multicore processor setups: the DRAM bus bandwidth. While caching and other techniques have aided this issue in other computational problems, linear solvers generally are still limited by the number of reads per cycle. By using an FPGA we can read and write a very large number of data points per clock cycle, removing this bottleneck.&lt;/p&gt;
&lt;p&gt;Through the use of extensive pipelining, the task interval is shortened to only one cycle for computing a single new approximation value. Since all BRAM and DSP pairs can be operated in parallel, this leads to 24 cycles per iteration.&lt;/p&gt;
&lt;h1 id="results"&gt;Results&lt;/h1&gt;
&lt;p&gt;&lt;img src="https://dondrews.github.io/img/fpga_plot.png" alt="Plot"&gt;&lt;/p&gt;
&lt;p&gt;Due to the fixed point arithmetic being used on the FPGA, we did not expect that the results would exactly match the analytical solution. For our purposes, we ran 5000 Jacobi iterations and compared the boundary value problem solution to a result computing in MATLAB.&lt;/p&gt;
&lt;p&gt;The computed solution of the FPGA is generally correct, but there is a large amount of error for $y$ close to $0$. We think this is because of the uneven rounding in the multiplication and addition. When multiple adjacent values of $y$ become $0$, this is a steady state for the algorithm since the next approximation is computed as a linear combination of its neighbors. This fact combined with rounding toward 0 in all cases is our hypothesis as to why this phenomenon occurs.&lt;/p&gt;
&lt;p&gt;Performance on the FPGA for domains this size is primarily limited by the slow serial communications between computer and FPGA used in our current implementation. However, in more advanced implementations with different hardware busses this is an easy limitation to overcome. Therefore we will focus on the computational speed only in our analysis. The FPGA we are currently testing on (a Xilinx Artix 7 on a Basys 3 development board) has a clock speed of 100MHz. Accounting for 24 clock cycles per iteration with 5000 iterations required, the full computation is completed in 1.2ms. Using the current design, the domain could be increased to 1280 points without any loss in speed by using more area. Further extensions of the domain would scale linearly from this point, until the BRAM capacity on the FPGA is reached.&lt;/p&gt;</content></item><item><title>USB Controller with STM32</title><link>https://dondrews.github.io/posts/usb-controller-with-stm32/</link><pubDate>Mon, 07 Dec 2020 00:00:00 +0000</pubDate><guid>https://dondrews.github.io/posts/usb-controller-with-stm32/</guid><description>&lt;p&gt;This project originally started nearly six years ago, when my friend and I patched together a prototype in my garage over the course of a week. It was constructed out of breadboard pushbuttons, birch plywood, an Arduino, and lots of glue. There were many issues with that version, including a patchwork driver, analog/digital interference, and unworkable wire management.&lt;/p&gt;
&lt;p&gt;In 2020 we decided to revive the project, with the goal of fixing all the aforementioned issues, as well as providing a clean and ergonomic exterior. The goal was to have a generalized controller/gamepad for use with computer games. This time, we were able to succeed in that pursuit. Below I will elaborate on our design process.&lt;/p&gt;</description><content>&lt;p&gt;This project originally started nearly six years ago, when my friend and I patched together a prototype in my garage over the course of a week. It was constructed out of breadboard pushbuttons, birch plywood, an Arduino, and lots of glue. There were many issues with that version, including a patchwork driver, analog/digital interference, and unworkable wire management.&lt;/p&gt;
&lt;p&gt;In 2020 we decided to revive the project, with the goal of fixing all the aforementioned issues, as well as providing a clean and ergonomic exterior. The goal was to have a generalized controller/gamepad for use with computer games. This time, we were able to succeed in that pursuit. Below I will elaborate on our design process.&lt;/p&gt;
&lt;h1 id="firmware"&gt;Firmware&lt;/h1&gt;
&lt;p&gt;&lt;a href="https://github.com/DonDrews/MOBAC2"&gt;GitHub Repo&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;One of the main goals was to have the controller be portable and simple to use. To that end, we decided to make a standard USB HID (Human Interface Device). This would allow it to be plugged into any computer and used without driver installations or custom programs, just like a standard USB keyboard or mouse. In fact, the controller enumerates as both a keyboard and a mouse on startup, and provides mouse input through the joystick, and keyboard input through the buttons. While this is a fairly simple paradigm, there were a few intricacies.&lt;/p&gt;
&lt;p&gt;One of the main downsides to a naive implementation of the joystick-to-mouse mapping is that different uses require different schemes. In some cases, moving the pointer based on the direction of the joystick is the most natural. In others, having the pointer locked to the position of the joystick is best. The USB HID standard refers to these as &amp;ldquo;relative&amp;rdquo; and &amp;ldquo;absolute&amp;rdquo; positioning respectively. Unfortunately, this property is stored in the device descriptor, and is therefore static between enumerations. To circumvent this, our controller is always in absolute mode, but can emulate relative movement based on a toggle switch.&lt;/p&gt;
&lt;p&gt;After writing the device descriptor, I implemented the USB functionality using the ST-provided middleware. Interfacing with the hardware was simple, and was just a matter of reading GPIOs and setting up the internal ADC channels for the joystick. Outside of one difficult-to-trace polling interval bug, the development process thankfully had few hiccups.&lt;/p&gt;
&lt;h1 id="electrical"&gt;Electrical&lt;/h1&gt;
&lt;p&gt;&lt;img src="https://dondrews.github.io/img/controller-wiring.jpg" alt="Controller Wiring"&gt;&lt;/p&gt;
&lt;p&gt;At the heart of the controller is an stm32f042k6t6 microcontroller on a Nucleo development board. It was chosen for its low price, USB support, small form-factor and sufficient GPIO. Few micros seemed to fit these criterion, but the Nucleo ended up working out nicely. One oversight was that not all GPIO are usable in the default configuration, as some are tied to other functions such as the FTDI communication with the host computer. However, by desoldering a few 0603 jumpers, this was resolved.&lt;/p&gt;
&lt;p&gt;As with any physical switch interface, debouncing is required. Testing with an oscilloscope revealed that the maximum bounce time for these buttons was about 2ms. We decided that, given the amount of buttons, implementing this in software was the best choice. Power for the controller is provided by the USB 5v connection, which is stepped down by an onboard 3.3v regulator.&lt;/p&gt;
&lt;h1 id="contruction"&gt;Contruction&lt;/h1&gt;
&lt;p&gt;To avoid the mess of last time, we opted to 3d print all of the shell-pieces for the controller. My friend first carved controllers into Styrofoam blocks to model the ergonomics and button placement, and then measured the dimensions and modeled in CAD. It took a few revisions to work out the kinks, but the final shell is reasonably comfortable and sturdy. A few last-minute edits were made with a hacksaw.&lt;/p&gt;
&lt;p&gt;&lt;img src="https://dondrews.github.io/img/controller-cad.png" alt="Controller CAD"&gt;&lt;/p&gt;
&lt;p&gt;After cleaning out the supports and accumulating all the necessary parts, actual construction only took one day to complete. The joystick was soldered to a protoboard, which was epoxied to the shell with a slab of birch plywood. This protoboard was also used for interfacing grounding and power. All of the connections to the microcontroller had female breadboard headers attached, to allow for modifications in the future. After all the connections were soldered, and the wires were squeezed into the shell and taped up, we were happy to find that the joystick and most of the buttons functioned as expected. The remaining buttons were fixed the following week.&lt;/p&gt;
&lt;p&gt;&lt;img src="https://dondrews.github.io/img/controller-print.png" alt="Controller Print"&gt;&lt;/p&gt;
&lt;h1 id="conclusion"&gt;Conclusion&lt;/h1&gt;
&lt;p&gt;While the controller isn&amp;rsquo;t quite as easy to use as we were hoping, it does function as a working USB controller. In addition, it is on a much stronger technological footing than the previous attempt. We will probably take a break from this project for a while, but in the future we hope to make more controllers with displays, dedicated PCBs, and sleeker ergonomics.&lt;/p&gt;</content></item><item><title>Raspberry Pi LCD Kernel Driver</title><link>https://dondrews.github.io/posts/raspberry-pi-lcd-kernel-driver/</link><pubDate>Sat, 14 Nov 2020 00:00:00 +0000</pubDate><guid>https://dondrews.github.io/posts/raspberry-pi-lcd-kernel-driver/</guid><description>&lt;p&gt;Just to preface, this was done as an educational exercise. There are great existing user space libraries for interfacing with the well-loved st7036 chipset. However, I thought it would be an interesting challenge to write a kernel module for raspberry pi that implemented a character device driver at the register level. Previously, I wrote a driver for this display for stm32, so my goal was to focus on the kernel aspects rather than the interface, which I copied with few changes.&lt;/p&gt;</description><content>&lt;p&gt;Just to preface, this was done as an educational exercise. There are great existing user space libraries for interfacing with the well-loved st7036 chipset. However, I thought it would be an interesting challenge to write a kernel module for raspberry pi that implemented a character device driver at the register level. Previously, I wrote a driver for this display for stm32, so my goal was to focus on the kernel aspects rather than the interface, which I copied with few changes.&lt;/p&gt;
&lt;p&gt;This project, like many others, involved more reading than coding or building. Thankfully, there was great information to be found online, in places such as the &lt;a href="https://lwn.net/Kernel/LDD3/"&gt;Linux Device Drivers book&lt;/a&gt; and the &lt;a href="https://www.raspberrypi.org/app/uploads/2012/02/BCM2835-ARM-Peripherals.pdf"&gt;Broadcom peripherals datasheet&lt;/a&gt;. There were a few topics that were not well documented, such as the creation of /dev entries and which of the several delay functions to use for a given scenario, but after some searching I found answers to these as well. As for the driver itself, it has a fairly standard topology. On module initialization, a virtual memory page for the GPIO registers is mapped, and startup commands are sent to the screen. Since Raspbian supports it, udev is utilized to create the /dev entry for the character device. Reads simply return a static message, and writes are sent over the bus to the screen one nibble at a time. While the operations in this driver are basic, I think it was a good starting place for kernel-side development. I hope to work on a network or block device driver, and utilize more advanced features in the future. The code for this driver is &lt;a href="https://github.com/DonDrews/linux_driver_tests"&gt;here&lt;/a&gt;. Included in the repository is a small script to write to the screen from stdin.&lt;/p&gt;</content></item><item><title>Remote Control Car</title><link>https://dondrews.github.io/posts/remote-control-car/</link><pubDate>Mon, 03 Aug 2020 00:00:00 +0000</pubDate><guid>https://dondrews.github.io/posts/remote-control-car/</guid><description>&lt;p&gt;The goal of this project was to create a small and simple RC car using only materials that were on hand. While most RC devices are operated off a radio transmitter and receiver running directly into a motor controller, I opted for a more standard robotics approach of using an on-board computer (specifically a Raspberry Pi 2). This would then have a Wi-Fi dongle where it can communicate with a controlling computer with a gamepad for driving controls. Having an OBC also makes running a video feed significantly easier.&lt;/p&gt;</description><content>&lt;p&gt;The goal of this project was to create a small and simple RC car using only materials that were on hand. While most RC devices are operated off a radio transmitter and receiver running directly into a motor controller, I opted for a more standard robotics approach of using an on-board computer (specifically a Raspberry Pi 2). This would then have a Wi-Fi dongle where it can communicate with a controlling computer with a gamepad for driving controls. Having an OBC also makes running a video feed significantly easier.&lt;/p&gt;
&lt;p&gt;The first step was to assemble the mechanical side of the car. I did not have any motors on hand, but luckily an old, broken stereo had a CD read head with a sufficiently powerful motor and gearing. Bending and cutting this read head assembly, and adding a wire coat hanger as an axle, provided a workable drive assembly.&lt;/p&gt;
&lt;p&gt;&lt;img src="https://dondrews.github.io/img/gearbox.jpg" alt="Gearbox of the RC car"&gt;&lt;/p&gt;
&lt;p&gt;As seen in the title image, I cut some wooden wheels out of plywood and attached a servo motor with the front axle. Lots of the work could have been cleaner, but it is a functional base for adding tech on top.&lt;/p&gt;
&lt;p&gt;Moving onto the electrical side, the Raspberry Pi GPIO cannot source enough current to power the motor nor the servo. Therefore, a power board is required to control these peripherals. The only power source I have on hand is 9 volt batteries, but the motor and the servo both require 5 volts to operate within specification. Thankfully, I had a single L7805 linear regulator around to use for this conversion. A linear regulator is not the ideal choice for this application, but it would be functional with enough cooling.&lt;/p&gt;
&lt;p&gt;&lt;img src="https://dondrews.github.io/img/rc-car-schematic.png" alt="Schematic of the RC car"&gt;&lt;/p&gt;
&lt;p&gt;The above schematic is, to my knowledge, a commonplace implementation of this scheme. The motors are controlled through an H-bridge, using the body diodes of the MOSFETs to handle inductive flyback. The 3.3v logic level of the Raspberry Pi is not sufficient to put the FETs into full conduction, so two inverting NPN switches are used in series for each input (a single FET each would have been better, but I didn&amp;rsquo;t have any extras). The 5v power rail has two smoothing capacitors to handle low and high frequency ripple along with an LED to indicate power. The servo is connected to the 5v rail and a Raspberry Pi pin. Lastly an indicator LED is in place, that I&amp;rsquo;ll likely use to show Wi-Fi connection in the future. The design was first tested on a breadboard, and later moved to a perfboard. In order to control heat dissipation from the regulator, part of an old GPU heatsink was cut off and attached.&lt;/p&gt;
&lt;p&gt;&lt;img src="https://dondrews.github.io/img/heatsink.jpg" alt="Heatsink jankily attached to this LDO"&gt;&lt;/p&gt;
&lt;p&gt;As with anything electrical, I always fear some oversight or edge case not considered, but this board seems to be functional for the time being. Once I learn more about electronics, I may change the design entirely.&lt;/p&gt;
&lt;p&gt;The last part I implemented was the &lt;a href="https://github.com/DonDrews/rc-car-control"&gt;software&lt;/a&gt;. It seemed that just some simple python scripts should be up to the task. I attached an unused Logitech C720 webcam to one of the host USB ports on the Pi. Using OpenCV, images are captured from the camera, resized to 480p, and encoded into a JPEG format. A TCP connection is established with the control computer using python sockets, and each image is sent independently over this link. On the control side, the images are decoded and displayed. The latency of this setup is suboptimal - around 250ms - due to both the inherent latency of the C720 and the time taken to encode each image (about 70ms). Certainly gains could be had by using GPU image compression, or even a dedicated video format like H.264. However, in this situation I felt that the current setup provided adequate performance to make the additional complexity not worthwhile.&lt;/p&gt;
&lt;p&gt;In another python thread, the control computer receives events from a USB gamepad and translates them into power and steering values before sending them over the same TCP port to the on board computer. Originally I used the gpiozero library for outputting the PWM signals, but realized that this did not take advantage of the existing PWM hardware and used a software emulation instead. An oscilloscope revealed that the accuracy of the pulse widths was inadequate, especially on the servo line. After some searching, I switched to the pigpio library which allows use of the hardware PWM, and the issue was resolved.&lt;/p&gt;
&lt;p&gt;After the mechanical, electrical, and software components were completed, I realized that I did not have a Wi-Fi dongle and that the servo I had installed was broken. Originally I had also planned to power the Raspberry Pi from the power board, but the L7805 was unable to supply enough stable current for reliable operation. A cellphone &amp;ldquo;power bank&amp;rdquo; was able to fix this issue, but overall the car was not able to be completed due to the other issues. Below is the current state of the car; it has the motor control and video feed operational.&lt;/p&gt;
&lt;p&gt;&lt;img src="https://dondrews.github.io/img/rc-full-layout.jpg" alt="The full electrical of the rc car on a table"&gt;&lt;/p&gt;
&lt;p&gt;Hopefully in the future I can obtain these last two parts and install all the boards onto the chassis. For the time being, the project is a proof of concept with most of the desired functionality. When the project is completed, this post will be updated.&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;</content></item><item><title>About</title><link>https://dondrews.github.io/about/</link><pubDate>Sat, 27 Jun 2020 00:00:00 +0000</pubDate><guid>https://dondrews.github.io/about/</guid><description>&lt;p&gt;Welcome! I am Donovan Drews, and this is my website covering various projects I dabble with on my spare time. Currently I am taking a career break to work as a vegetable farmer. Professionally, my focus is FPGAs, embedded systems, and software defined radio. Before all this, I was studying mathematics at UC San Diego.&lt;/p&gt;
&lt;p&gt;The topics contained here can be fairly varied, but generally center around embedded systems. If you have any questions you can reach me at &lt;a href="mailto:donovancarldrews@gmail.com"&gt;donovancarldrews@gmail.com&lt;/a&gt;.&lt;/p&gt;</description><content>&lt;p&gt;Welcome! I am Donovan Drews, and this is my website covering various projects I dabble with on my spare time. Currently I am taking a career break to work as a vegetable farmer. Professionally, my focus is FPGAs, embedded systems, and software defined radio. Before all this, I was studying mathematics at UC San Diego.&lt;/p&gt;
&lt;p&gt;The topics contained here can be fairly varied, but generally center around embedded systems. If you have any questions you can reach me at &lt;a href="mailto:donovancarldrews@gmail.com"&gt;donovancarldrews@gmail.com&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://github.com/DonDrews"&gt;GitHub&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://www.linkedin.com/in/donovan-d-b05237132/"&gt;LinkedIn&lt;/a&gt;&lt;/p&gt;</content></item><item><title>Interactive Math Webpage</title><link>https://dondrews.github.io/posts/interactive-math-webpage/</link><pubDate>Sat, 27 Jun 2020 00:00:00 +0000</pubDate><guid>https://dondrews.github.io/posts/interactive-math-webpage/</guid><description>&lt;p&gt;I&amp;rsquo;ve always been interested in visual descriptions of math, and I think interactive displays are a useful educative tool for developing intuition. Making a website to visually display the terms of the complex exponential function (as a Maclaurin series) has been on the to-do list for a while. Problem is, I am not a web developer, and have never worked with web technologies.&lt;/p&gt;
&lt;p&gt;I had a few days open so I decided to dig into the details and make this webpage. I think my inexperience with JS, HTML, and CSS show through but overall I am happy with the result. If I have any more ideas for these sorts of webpages I might continue them as a series in the future.&lt;/p&gt;</description><content>&lt;p&gt;I&amp;rsquo;ve always been interested in visual descriptions of math, and I think interactive displays are a useful educative tool for developing intuition. Making a website to visually display the terms of the complex exponential function (as a Maclaurin series) has been on the to-do list for a while. Problem is, I am not a web developer, and have never worked with web technologies.&lt;/p&gt;
&lt;p&gt;I had a few days open so I decided to dig into the details and make this webpage. I think my inexperience with JS, HTML, and CSS show through but overall I am happy with the result. If I have any more ideas for these sorts of webpages I might continue them as a series in the future.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://dondrews.github.io/complex-exponential/"&gt;Website&lt;/a&gt;&lt;/p&gt;</content></item></channel></rss>